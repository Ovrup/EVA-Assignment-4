{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ThirdCodeAssignment4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ovrup/EVA-Assignment-4/blob/master/ThirdCodeAssignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ve93hJR87g0",
        "colab_type": "text"
      },
      "source": [
        "**3rd Code Assignment 4**\n",
        "\n",
        "The same architecture from second code is used. But only difference is batch normalization is used. \n",
        "The no of parameters is 13,278. Also I used learning rate scheduler for Adam optimizer. With batch size of 128 the final validation accuracy improved from the 2nd code to 99.11% after 20 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir7AeWMDhuSJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23905322-508a-4772-f0a7-871b9f7fc0aa"
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSjrr3Izh3pC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing all necessary modules in Keras\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRRChybch31I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mnist.load_data() function download the MNIST data set(Images of hand written digits) & divide it into training set & test set.\n",
        "# X_train holds the training samples & y_train holds the corresponding labels for training data. Likewise, X_test holds test data & y_test has the labels.\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjptflFrh37_",
        "colab_type": "code",
        "outputId": "4cb2396d-cb04-4917-8b7f-1385ef0d3d70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "# X_train is a matrix which has 60K images each of size 28*28. X_train.shape returns the shape of the total training set\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "# visulaization of the 1st sample of training set which is an image of 5 as shown below.\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f649b960390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1YYHLkMh4C1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The train & test set are 3D matrix.The training set is of shape (60000,28,28) & test set is (10000,28,28). But here the CNN model expects\n",
        "# the input shape to be 4D i.e (no of samples,height,width,channel).Channel implies whether the image is gray scale or colour(RGB). In case of\n",
        "# RGB image the 4th dimension would be 3. In this case the images are gray scale. Hence, it is 1. That's why training & test set are reshaped into\n",
        "# matrices of shape (60000,28,28,1) & (10000,28,28,1) respectively.\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HXK38mDh4JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The data sets are matrices which has values between 0-255. These are normally the pixel values. It is a good practice to normalise the data.\n",
        "#  Hence, dividing by 255 scales down each values between 0-1. But before doing that the data set values has to be converted to float to make sure\n",
        "# after dividing by 255 these are stored as float.\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz_GaFwXh4K8",
        "colab_type": "code",
        "outputId": "42e8e148-8964-49df-e3b9-08fa8cbead0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# 1st 10 labels for training set. As printed below the 1st element is 5 which implies the 1st image of training set is of digit 5 and so on. \n",
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4HAeMk-h4Op",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "# As shown above the label matrix(Y_train & Y_test) holds values that implies what digit the image is about. So, keras may find some relational order\n",
        "# between these values. To avoid this problem we hot encode the matrix into a binary matrix. This matrix has number of columns equal to the number\n",
        "# of classes(10 columns in this scenario). Each row defines the label of one sample point in data set & has only one '1' & others are '0'. '1' at\n",
        "# particular index position implies the digit equal to the column number. For example, the 1st row(1st sample of training data set) has '1' at column\n",
        "# number 5(starting from 0) which means this is image of digit 5.\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices \n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnEjyfkyh4RJ",
        "colab_type": "code",
        "outputId": "7fcfa0c0-6fe5-4c10-88cf-218641ac03e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Label matrix hot encoded into binary matrix\n",
        "Y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy_ibvgrX4Ek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "2a4ba51b-b947-4ca6-ee5a-c057e73c7cf0"
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Input = 28*28*1\n",
        "model.add(Convolution2D(10, kernel_size = (3,3), activation = 'relu', input_shape = (28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Input = 26*26*10\n",
        "model.add(Convolution2D(16, kernel_size = (3,3), activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "# Input = 24*24*16\n",
        "model.add(Convolution2D(16, kernel_size = (3,3), activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Input = 22*22*16\n",
        "model.add(Convolution2D(10, kernel_size=(1,1), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "# Input = 22*22*10\n",
        "model.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "# Input = 11*11*10\n",
        "model.add(Convolution2D(16, kernel_size=(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "# Input = 9*9*16\n",
        "model.add(Convolution2D(16, kernel_size=(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# Input = 7*7*16\n",
        "model.add(Convolution2D(10, kernel_size=(1,1), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "# Input = 7*7*10\n",
        "model.add(Convolution2D(10, 7))\n",
        "\n",
        "# Input = 1*1*10\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRGYZKoyiUct",
        "colab_type": "code",
        "outputId": "0e53450d-8040-4be1-fb2a-1d81770f941a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "# summary() function displays the model structure i.e for each layer how many parameters used, what is the shape of output image\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 10)        100       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 16)        1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 16)        64        \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 22, 22, 10)        170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 22, 22, 10)        40        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 16)          1456      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 16)          2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 16)          64        \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          170       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 13,278\n",
            "Trainable params: 13,090\n",
            "Non-trainable params: 188\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzhq9Pk3oK1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "def scheduler(epoch,lr):\n",
        "  decay = 0.1\n",
        "  return round(0.01 * 1/(1 + decay * epoch) , 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKkc6pAmiUmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model with Adam optimizer. Since this is multi class problem (10 classes) 'categorical_crossentropy' is used as loss function.\n",
        "# accuracy is used as metrics w.hich means while training this accuracy metrics will be monitored.\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr = 0.01),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZcCcCL3iUte",
        "colab_type": "code",
        "outputId": "72ef85a9-4170-40e3-bb06-416c9d4019f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        }
      },
      "source": [
        "# Train the model with fit() which takes the training data set along with the label matrix. Epoch means one round of the whole data set. Batch size\n",
        "# determines in an epoch how many images to be processed parallelly. Batch size 32 means in an epoch in one iteration 32 images are processed.\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=20,validation_data = (X_test,Y_test), callbacks=[LearningRateScheduler(scheduler,verbose = 1)])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0574 - val_acc: 0.9864\n",
            "Epoch 2/20\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0090909091.\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0404 - val_acc: 0.9904\n",
            "Epoch 3/20\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0083333333.\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0446 - val_acc: 0.9905\n",
            "Epoch 4/20\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0076923077.\n",
            "60000/60000 [==============================] - 6s 99us/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.0507 - val_acc: 0.9869\n",
            "Epoch 5/20\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0071428571.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0420 - val_acc: 0.9903\n",
            "Epoch 6/20\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0066666667.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0084 - acc: 0.9971 - val_loss: 0.0475 - val_acc: 0.9894\n",
            "Epoch 7/20\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.00625.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0539 - val_acc: 0.9895\n",
            "Epoch 8/20\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0058823529.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0028 - acc: 0.9990 - val_loss: 0.0489 - val_acc: 0.9914\n",
            "Epoch 9/20\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0055555556.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0043 - acc: 0.9985 - val_loss: 0.0506 - val_acc: 0.9912\n",
            "Epoch 10/20\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0052631579.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0666 - val_acc: 0.9885\n",
            "Epoch 11/20\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.005.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0661 - val_acc: 0.9887\n",
            "Epoch 12/20\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0047619048.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0465 - val_acc: 0.9908\n",
            "Epoch 13/20\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0045454545.\n",
            "60000/60000 [==============================] - 6s 96us/step - loss: 0.0020 - acc: 0.9994 - val_loss: 0.0484 - val_acc: 0.9913\n",
            "Epoch 14/20\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0043478261.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0482 - val_acc: 0.9916\n",
            "Epoch 15/20\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0041666667.\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0507 - val_acc: 0.9908\n",
            "Epoch 16/20\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.004.\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0629 - val_acc: 0.9899\n",
            "Epoch 17/20\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.0038461538.\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0450 - val_acc: 0.9915\n",
            "Epoch 18/20\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0037037037.\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 7.1454e-04 - acc: 0.9998 - val_loss: 0.0560 - val_acc: 0.9902\n",
            "Epoch 19/20\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0035714286.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0586 - val_acc: 0.9904\n",
            "Epoch 20/20\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.0034482759.\n",
            "60000/60000 [==============================] - 6s 95us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0601 - val_acc: 0.9911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f646a57c668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUTlV4ooiU1D",
        "colab_type": "code",
        "outputId": "61810d76-7699-48ea-cc15-e8c8b297b74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Now the model is trained which means the weights are optimized. model.evaluate() predicts the classes of each image in test set & then calculate\n",
        "# test set loss & accuracy.\n",
        "score = model.evaluate(X_test, Y_test, verbose=1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 71us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAY1beNNiiXH",
        "colab_type": "code",
        "outputId": "54ec438e-ce32-450f-fe6c-d2c41f379295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# score is a vector that holds the test set loss & accuracy\n",
        "print(score)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.06012572128030022, 0.9911]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnHdifAZiieX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict the class of each image in test set & stores in y_pred matrix\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5tTsReFiik-",
        "colab_type": "code",
        "outputId": "ad7df996-9f26-4546-a5a0-0e6175018daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.89381624e-34 1.95441283e-30 1.91415622e-22 2.14775934e-19\n",
            "  0.00000000e+00 8.63854756e-23 0.00000000e+00 1.00000000e+00\n",
            "  7.02255522e-30 2.34762207e-19]\n",
            " [4.20968292e-19 3.75999988e-19 1.00000000e+00 1.04968605e-25\n",
            "  2.32166858e-28 3.86524023e-38 3.85722605e-16 6.87860356e-33\n",
            "  3.94914991e-31 1.58121087e-30]\n",
            " [2.07677962e-25 1.00000000e+00 3.00239563e-16 3.77938014e-21\n",
            "  3.79377693e-16 6.44734720e-18 7.75779146e-24 2.83737853e-16\n",
            "  6.05914555e-19 3.84222454e-20]\n",
            " [1.00000000e+00 4.60977648e-22 1.44035813e-21 1.12157492e-24\n",
            "  8.02689085e-24 4.22304654e-20 4.51021031e-15 1.18995457e-24\n",
            "  4.26019462e-21 9.39671585e-15]\n",
            " [1.19316297e-25 1.97211259e-27 1.49936445e-29 4.16410090e-26\n",
            "  1.00000000e+00 2.47182585e-22 9.60030406e-23 2.39585974e-28\n",
            "  1.04447567e-21 4.62110593e-11]\n",
            " [3.89025430e-23 1.00000000e+00 3.26567597e-17 5.01645485e-24\n",
            "  1.98022094e-15 1.50696243e-21 1.33501187e-23 4.60513285e-16\n",
            "  1.14621528e-18 2.46151657e-19]\n",
            " [0.00000000e+00 2.35427944e-24 3.16813319e-27 2.02914937e-34\n",
            "  1.00000000e+00 7.56558486e-29 0.00000000e+00 6.42361270e-24\n",
            "  3.37124619e-15 6.29988975e-19]\n",
            " [1.98741983e-28 9.10549352e-22 2.03670633e-23 1.28973974e-22\n",
            "  2.26992401e-18 7.76551914e-24 0.00000000e+00 8.53751026e-24\n",
            "  1.02633985e-19 1.00000000e+00]\n",
            " [2.47359032e-21 3.02661635e-36 3.40065458e-38 0.00000000e+00\n",
            "  4.45131443e-35 9.99995947e-01 3.99357123e-06 0.00000000e+00\n",
            "  1.06413334e-14 2.49124182e-21]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxd3j3uKmtUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShGbYmvH7l4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_14'):\n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qYgDEkt-C7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}